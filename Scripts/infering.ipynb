{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load checkingpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig, AutoTokenizer, GenerationConfig\n",
    "base_model = 'wadecc/Wat2c'\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "device = \"cuda:1\"  \n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=BitsAndBytesConfig(load_in_8bit=True),\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(),'..'))\n",
    "sys.path.append(project_root)\n",
    "from Utils.WatModuleParcer import WatModule\n",
    "from Utils.formatting import formated_c\n",
    "import re\n",
    "from tree_sitter import Language, Parser\n",
    "C_LANGUAGE = Language(f'{os.getcwd()}/Metrics/Codebleu/so/my-languages.so', 'c')\n",
    "parser = Parser()\n",
    "parser.set_language(C_LANGUAGE)\n",
    "\n",
    "var_pat = re.compile(r'((local|global)_\\d+)')\n",
    "func_declareation_pat = re.compile(r'\\s+call ([\\S\\$]+)[\\)\\n]+')\n",
    "def get_declaration(wat_block_str:str, wat_module:WatModule):\n",
    "    call_func_declarations = []\n",
    "    for call_func_id in func_declareation_pat.findall(wat_block_str):\n",
    "        if call_func_id.startswith('$'):\n",
    "            call_func_id = re.escape(call_func_id) \n",
    "        pat_func_call_declaration = re.compile(rf'(  \\(func {call_func_id} .*?\\))\\n')\n",
    "        match = pat_func_call_declaration.search(wat_module.content)\n",
    "        if match:\n",
    "            call_func_declaration = match.group(1)\n",
    "            if call_func_declaration in call_func_declarations:\n",
    "                continue\n",
    "            call_func_declarations.append(call_func_declaration)\n",
    "    return '\\n'.join(call_func_declarations)\n",
    "\n",
    "def is_error(c_text: str) -> bool:\n",
    "    root_node = parser.parse(bytes(c_text, 'utf8')).root_node\n",
    "    return root_node.has_error\n",
    "\n",
    "def get_prompt(wat_block_str:str, wat_module:WatModule):\n",
    "    return f\"\"\"\n",
    "### Instruction:\n",
    "Decompile the provided WAT snippet into an equivalent C code snippet, ensuring:\n",
    "- Logical structure and functionality match the original WAT code.\n",
    "- '<< >>' markers are preserved to indicate incomplete segments.\n",
    "- Replace strings in the decompiled C code with their WAT data segment offsets. The format to represent these strings should be '(i32|i64.const offset)'.\n",
    "- For variables in the decompiled C snippet, name them based on the value of the offset in wat snippet (i.e., i32.load offset=xxx), local variables are named local_{{offset}}.\n",
    "- Even if the part of wat code is dead code, decompile it to c.\n",
    "\n",
    "### Input(wat code):\n",
    "The `Call_Func Declaration` specifies the number of params and return values\n",
    "[Call_Func Declarations]\n",
    "{get_declaration(wat_block_str, wat_module)}\n",
    "[/Call_Func Declarations]\n",
    "[Wat]\n",
    "{wat_block_str}\n",
    "[/Wat]\n",
    "### Response:\n",
    "\"\"\"\n",
    "rodata_pat = re.compile(r'\\$\\.\\w+ \\(\\w\\d+\\.const (\\d+)\\)')\n",
    "def CLM_decompile(\n",
    "    wat_path:str,\n",
    "    invoke_list:list[str], \n",
    "    max_str_len:int = 2000,\n",
    "    max_new_tokens=8000,\n",
    "    ):\n",
    "    wat_module = WatModule()\n",
    "    wat_module.parse_wat(wat_path,max_block_str_len=max_str_len)\n",
    "    blocks = wat_module.blocks\n",
    "    ordered_funcs = wat_module.get_ordered_funcs(invoke_list=invoke_list)\n",
    "    Decompile_result = []\n",
    "    error_funcs = []\n",
    "    for i, wat_func_id in enumerate(ordered_funcs):\n",
    "        wat_func_blocks:dict = blocks[wat_func_id]\n",
    "        func_c = ''\n",
    "        for i, (wat_block_id, wat_block_str) in enumerate(wat_func_blocks.items()):\n",
    "            eval_prompt = get_prompt(wat_block_str, wat_module)\n",
    "            if len(eval_prompt) > 8000:\n",
    "                print('Too long input(8000)')\n",
    "                break\n",
    "            block_dict = wat_module.get_const_strs(wat_block_str)\n",
    "            model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(device)\n",
    "            model_input = {key: value for key, value in model_input.items()}\n",
    "            model.eval()            \n",
    "            with torch.no_grad():\n",
    "                generated_tokens = model.generate(\n",
    "                    **model_input, \n",
    "                    max_new_tokens=max_new_tokens,\n",
    "                    use_cache=True,\n",
    "                    pad_token_id=tokenizer.eos_token_id\n",
    "                )\n",
    "                decoded_output = tokenizer.decode(generated_tokens[0].cpu().numpy(), skip_special_tokens=True)\n",
    "            block_c = decoded_output[decoded_output.index(\"### Response:\")+14:]\n",
    "            for key, val in block_dict.items():\n",
    "                block_c = block_c.replace(key,val.replace('\\\\0a','\\\\n'))\n",
    "            matches = rodata_pat.finditer(block_c)\n",
    "            for match in matches:\n",
    "                number = int(match.group(1))\n",
    "                if number >=  65536:\n",
    "                    continue\n",
    "                block_c = block_c.replace(match.group(),chr(number))\n",
    "            if i == 0:\n",
    "                func_c += block_c\n",
    "            elif wat_block_id.startswith('$'):\n",
    "                func_c = func_c.replace(f\"<< {wat_block_id[1:]} >>\",block_c)\n",
    "            else:\n",
    "                func_c = func_c.replace(f\"<< {wat_block_id[2:-2]} >>\",block_c)\n",
    "        if is_error(func_c):\n",
    "            error_funcs.append(i)\n",
    "        Decompile_result.append(func_c)\n",
    "    return '\\n'.join(Decompile_result), \\\n",
    "        not error_funcs, \\\n",
    "        '\\n'.join([x for j, x in enumerate(Decompile_result) if j not in error_funcs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result, _, _ = CLM_decompile(\n",
    "    wat_path = 'xxx.wat',\n",
    "    invoke_list = ['main']                \n",
    ")\n",
    "print(formated_c(result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sxy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
